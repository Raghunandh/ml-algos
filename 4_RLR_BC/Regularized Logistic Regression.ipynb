{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression\n",
    "\n",
    "\n",
    "\n",
    "This notebook is an implemention of Regularized Logistic Regression to predict whether microchips from a fabrication plant passes quality assurance (QA). During QA, each microchip goes through various tests to ensure\n",
    "it is functioning correctly.\n",
    "Lets suppose we have the\n",
    "test results for some microchips on two different tests. From these two tests,\n",
    "we would like to determine whether the microchips should be accepted or\n",
    "rejected. To help us make the decision, we have a dataset of test results\n",
    "on past microchips, from which we can build a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset as a dataframe 'df'\n",
    "df = pd.read_table('data2.txt', delimiter=',', names=('Test_1', 'Test_2', 'Accepted?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_1</th>\n",
       "      <th>Test_2</th>\n",
       "      <th>Accepted?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.69956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.68494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.69225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.50219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.46564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Test_1   Test_2  Accepted?\n",
       "0  0.051267  0.69956          1\n",
       "1 -0.092742  0.68494          1\n",
       "2 -0.213710  0.69225          1\n",
       "3 -0.375000  0.50219          1\n",
       "4 -0.513250  0.46564          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      "Test_1       118 non-null float64\n",
      "Test_2       118 non-null float64\n",
      "Accepted?    118 non-null int64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 2.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the columns of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_1</th>\n",
       "      <th>Test_2</th>\n",
       "      <th>Accepted?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496654</td>\n",
       "      <td>0.519743</td>\n",
       "      <td>0.502060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.830070</td>\n",
       "      <td>-0.769740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.372120</td>\n",
       "      <td>-0.254385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.006336</td>\n",
       "      <td>0.213455</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.478970</td>\n",
       "      <td>0.646562</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.070900</td>\n",
       "      <td>1.108900</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Test_1      Test_2   Accepted?\n",
       "count  118.000000  118.000000  118.000000\n",
       "mean     0.054779    0.183102    0.491525\n",
       "std      0.496654    0.519743    0.502060\n",
       "min     -0.830070   -0.769740    0.000000\n",
       "25%     -0.372120   -0.254385    0.000000\n",
       "50%     -0.006336    0.213455    0.000000\n",
       "75%      0.478970    0.646562    1.000000\n",
       "max      1.070900    1.108900    1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Summary Statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "Lets create a scatterplot with the test scores to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGtCAYAAACLJXdUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCgZERERy7v8HB3A6/zELoQoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbbd82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rejected = df[df['Accepted?']==0]\n",
    "accepted = df[df['Accepted?']==1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,7))  \n",
    "ax.scatter(accepted['Test_1'], accepted['Test_2'], c='g', marker='o', label='Accepted')  \n",
    "ax.scatter(rejected['Test_1'], rejected['Test_2'], c='r', marker='o', label='Rejected')  \n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "ax.set_xlabel('Test1 Score')\n",
    "ax.set_ylabel('Test2 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows that our dataset cannot be separated into positive and\n",
    "negative examples by a straight-line through the plot. Therefore, a straight-forward application of logistic regression will not perform well on this dataset\n",
    "since logistic regression will only be able to find a linear decision boundary.\n",
    "\n",
    "One way to deal with this using a linear technique like logistic regression is to construct features that are derived from polynomials of the original features. We can try creating a bunch of polynomial features to feed into the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following code, we will map the features into\n",
    "all polynomial terms of X1 and X2 up to the sixth power.\n",
    "\n",
    "As a result of this mapping, our vector of two features (the scores on\n",
    "two QA tests) has been transformed into a 28-dimensional vector. A logistic\n",
    "regression classifier trained on this higher-dimension feature vector will have\n",
    "a more complex decision boundary and will appear nonlinear when drawn in\n",
    "our 2-dimensional plot.\n",
    "\n",
    "While the feature mapping allows us to build a more expressive classifier,\n",
    "it is also more susceptible to overfitting. In the next part, we\n",
    "will implement regularized logistic regression to fit the data and also see how regularization can help combat the overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accepted?</th>\n",
       "      <th>X0</th>\n",
       "      <th>F10</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F30</th>\n",
       "      <th>F31</th>\n",
       "      <th>F32</th>\n",
       "      <th>F40</th>\n",
       "      <th>F41</th>\n",
       "      <th>...</th>\n",
       "      <th>F51</th>\n",
       "      <th>F52</th>\n",
       "      <th>F53</th>\n",
       "      <th>F54</th>\n",
       "      <th>F60</th>\n",
       "      <th>F61</th>\n",
       "      <th>F62</th>\n",
       "      <th>F63</th>\n",
       "      <th>F64</th>\n",
       "      <th>F65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051267</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.025089</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>1.815630e-08</td>\n",
       "      <td>2.477505e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.008589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092742</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>-0.063523</td>\n",
       "      <td>-0.000798</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.043509</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>-0.020412</td>\n",
       "      <td>6.362953e-07</td>\n",
       "      <td>-4.699318e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>-0.013981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.213710</td>\n",
       "      <td>0.045672</td>\n",
       "      <td>-0.147941</td>\n",
       "      <td>-0.009761</td>\n",
       "      <td>0.031616</td>\n",
       "      <td>-0.102412</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>-0.049077</td>\n",
       "      <td>9.526844e-05</td>\n",
       "      <td>-3.085938e-04</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>-0.033973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>-0.188321</td>\n",
       "      <td>-0.052734</td>\n",
       "      <td>0.070620</td>\n",
       "      <td>-0.094573</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>-0.026483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>-0.013299</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>-0.023851</td>\n",
       "      <td>2.780914e-03</td>\n",
       "      <td>-3.724126e-03</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>-0.006679</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>-0.011978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.513250</td>\n",
       "      <td>0.263426</td>\n",
       "      <td>-0.238990</td>\n",
       "      <td>-0.135203</td>\n",
       "      <td>0.122661</td>\n",
       "      <td>-0.111283</td>\n",
       "      <td>0.069393</td>\n",
       "      <td>-0.062956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>-0.029315</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>-0.024128</td>\n",
       "      <td>1.827990e-02</td>\n",
       "      <td>-1.658422e-02</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>-0.013650</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>-0.011235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accepted?  X0       F10       F20       F21       F30       F31       F32  \\\n",
       "0          1   1  0.051267  0.002628  0.035864  0.000135  0.001839  0.025089   \n",
       "1          1   1 -0.092742  0.008601 -0.063523 -0.000798  0.005891 -0.043509   \n",
       "2          1   1 -0.213710  0.045672 -0.147941 -0.009761  0.031616 -0.102412   \n",
       "3          1   1 -0.375000  0.140625 -0.188321 -0.052734  0.070620 -0.094573   \n",
       "4          1   1 -0.513250  0.263426 -0.238990 -0.135203  0.122661 -0.111283   \n",
       "\n",
       "        F40       F41    ...          F51       F52       F53       F54  \\\n",
       "0  0.000007  0.000094    ...     0.000005  0.000066  0.000900  0.012278   \n",
       "1  0.000074 -0.000546    ...     0.000051 -0.000374  0.002764 -0.020412   \n",
       "2  0.002086 -0.006757    ...     0.001444 -0.004677  0.015151 -0.049077   \n",
       "3  0.019775 -0.026483    ...     0.009931 -0.013299  0.017810 -0.023851   \n",
       "4  0.069393 -0.062956    ...     0.032312 -0.029315  0.026596 -0.024128   \n",
       "\n",
       "            F60           F61       F62       F63       F64       F65  \n",
       "0  1.815630e-08  2.477505e-07  0.000003  0.000046  0.000629  0.008589  \n",
       "1  6.362953e-07 -4.699318e-06  0.000035 -0.000256  0.001893 -0.013981  \n",
       "2  9.526844e-05 -3.085938e-04  0.001000 -0.003238  0.010488 -0.033973  \n",
       "3  2.780914e-03 -3.724126e-03  0.004987 -0.006679  0.008944 -0.011978  \n",
       "4  1.827990e-02 -1.658422e-02  0.015046 -0.013650  0.012384 -0.011235  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(3, 'X0', 1)   # Insert a column of 1's at the end\n",
    "\n",
    "degree = 7\n",
    "X1 = df['Test_1']  \n",
    "X2 = df['Test_2']\n",
    "\n",
    "for i in range(1, degree):  \n",
    "    for j in range(0, i):\n",
    "        df['F' + str(i) + str(j)] = np.power(X1, i-j) * np.power(X2, j)\n",
    "\n",
    "# First 2 columns are not needed for the analysis so they can be removed from the dataframe\n",
    "df.drop('Test_1', axis=1, inplace=True)  \n",
    "df.drop('Test_2', axis=1, inplace=True)\n",
    "\n",
    "# Print first 5 rows of the updated dataframe\n",
    "df.head()         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe 'df' has been updated with the new columns F10 to F65 as shown above. Here, column names refer to the powers of X1 and X2 used to create those columns. For example, F32 refers to $X_1^3$ * $X_2^2$, where $X_1$ and $X_2$ are Test_1 and Test_2 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function and Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement code to compute the cost function and gradient for\n",
    "regularized logistic regression.\n",
    "\n",
    "Regularization is a term in the cost function that causes the algorithm to prefer \"simpler\" models (in this case, models will smaller coefficients). The theory is that this helps to minimize overfitting and improve the model's ability to generalize.\n",
    "\n",
    "The regularized cost function in logistic regression is:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m [-y^{(i)}log(h_\\theta(x^{(i)})) - (1-y^{(i)})log(1 - h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\theta_j^2 $$\n",
    "\n",
    "Note that we should not regularize the parameter $\\theta_0$. The gradient\n",
    "of the cost function is a vector where the j'th element is defined as follows:\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m}\\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)} \\;,\\;\\;\\;\\;\\; for\\; j=0 $$\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\Bigg(\\frac{1}{m}\\sum_{i=1}^{m} (h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\Bigg) + \\frac{\\lambda}{m} \\theta_j \\;,\\;\\;\\;\\;\\;for\\;j>0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the Regularized Cost function\n",
    "def costFunctionReg(theta, X, y, lambda_reg):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    regularized = (lambda_reg / 2 * len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    \n",
    "    J = np.sum(first - second) / (len(X)) + regularized\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to calculate gradient\n",
    "def gradientReg(theta, X, y, lambda_reg):  \n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "\n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "\n",
    "        if (i == 0):\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "        else:\n",
    "            grad[i] = (np.sum(term) / len(X)) + ((lambda_reg / len(X)) * theta[:,i])\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate Cost and Gradient for initial $\\theta$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost when theta is an array of zeros = 0.6931471805599454\n",
      "Gradient when theta is an array of zeros = [ 0.00847458  0.01878809  0.05034464  0.01150133  0.01835599  0.00732393\n",
      "  0.00819244  0.03934862  0.00223924  0.01286005  0.00309594  0.01997075\n",
      "  0.00432983  0.00338644  0.00583822  0.00447629  0.03103124  0.0010974\n",
      "  0.00631571  0.0004085   0.00726504  0.00137646]\n"
     ]
    }
   ],
   "source": [
    "# Set X and y\n",
    "cols = df.shape[1]  \n",
    "X2 = df.iloc[:,1:cols]  \n",
    "y2 = df.iloc[:,0:1]\n",
    "\n",
    "# Convert to numpy arrays and initalize the parameter array theta\n",
    "X2 = np.array(X2.values)  \n",
    "y2 = np.array(y2.values)  \n",
    "theta2 = np.zeros(X2.shape[1])\n",
    "\n",
    "learningRate = 0.01\n",
    "\n",
    "cost_0 = costFunctionReg(theta2, X2, y2, learningRate)\n",
    "gradient_0 = gradientReg(theta2, X2, y2, learningRate)\n",
    "print('Cost when theta is an array of zeros = {0}'.format(cost_0))\n",
    "print('Gradient when theta is an array of zeros = {0}'.format(gradient_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning parameters using fmin_tnc\n",
    "\n",
    "By using the function 'gradientReg', we don't actually perform gradient descent. We just compute a single gradient step. In the following steps, we use SciPy's optimization API to optimize the parameters, given functions to compute the cost and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculated using optimal theta is = 0.6930233952230453\n"
     ]
    }
   ],
   "source": [
    "result = opt.fmin_tnc(func=costFunctionReg, x0=theta2, fprime=gradientReg, args=(X2, y2, learningRate))  \n",
    "J_min = costFunctionReg(result[0], X2, y2, learningRate)\n",
    "print('Error calculated using optimal theta is = {0}'.format(J_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    h = sigmoid(X * theta.T)\n",
    "    predictions = (h>=0.5)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88%\n"
     ]
    }
   ],
   "source": [
    "theta_final = np.matrix(result[0])  \n",
    "predictions = predict(theta_final, X2)  \n",
    "correct_predictions = [1 if ((a == 1 and b == 1) or (a == 0 and b == 0)) else 0 for (a, b) in zip(predictions, y2)]  \n",
    "accuracy = (sum(map(int, correct_predictions)) % len(correct_predictions))  \n",
    "print('Accuracy = {0}%'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
